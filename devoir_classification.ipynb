{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import pandas as pnd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5213bb4",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Section 1: Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8be6f",
   "metadata": {},
   "source": [
    "<h2>1) Préparation de données</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f748d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =pnd.read_csv('diabetes.csv')#import\n",
    "X = np.array(dataset.drop(columns=['Outcome'])) #features\n",
    "y = np.array(dataset['Outcome']) #target\n",
    "#spilt data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52055be8",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Section 2: Neural network avec tensorflow</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207be9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a611a",
   "metadata": {},
   "source": [
    "<h2>2) Modèle de réseau de neurones</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = Sequential()\n",
    "# 2-a-1 & 2-a-2 & 2-a-3: Based on the dataset nature (binary classification)\n",
    "# Input shape is X_train.shape[1] (8 features)\n",
    "# Output is 1 neuron (binary classification)\n",
    "# Activation is sigmoid (for binary classification)\n",
    "output_layer = Dense(1, input_shape=(X_train.shape[1],), activation='sigmoid')\n",
    "model_nn.add(output_layer)\n",
    "\n",
    "# 2-c: Compile the model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model_nn.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 2-d: Train the model\n",
    "history = model_nn.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cd5cd",
   "metadata": {},
   "source": [
    "<h2>3) Prédiction en utilisant le modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd76e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_nn=model_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_nn=yhat_nn.flatten()\n",
    "yhat_nn_class = (yhat_nn > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_nn, bias_nn = model_nn.layers[0].get_weights()\n",
    "# Manual prediction using sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "manual_predictions = sigmoid(np.dot(X_test, W_nn) + bias_nn)\n",
    "manual_predictions = manual_predictions.flatten()\n",
    "manual_predictions_class = (manual_predictions > 0.5).astype(int)\n",
    "\n",
    "# 4-a & 4-b: Evaluate model\n",
    "# Training set evaluation\n",
    "train_predictions = model_nn.predict(X_train).flatten()\n",
    "train_predictions_class = (train_predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"Model Evaluation on Training Set:\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, train_predictions_class):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_train, train_predictions_class):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_train, train_predictions_class):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_train, train_predictions_class))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, train_predictions_class))\n",
    "\n",
    "# Test set evaluation\n",
    "print(\"\\nModel Evaluation on Test Set:\")\n",
    "print(\"-------------------------------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, yhat_nn_class):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, yhat_nn_class):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, yhat_nn_class):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, yhat_nn_class))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, yhat_nn_class))\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - yhat_nn\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(yhat_nn, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d63bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503925c",
   "metadata": {},
   "source": [
    "<h2>4) Evaluation du modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_params = (num_features * 1) + 1\n",
    "print(f\"Number of parameters (manual calculation): {num_params}\")\n",
    "\n",
    "# Display model details\n",
    "model_nn.summary()\n",
    "\n",
    "# 2-h: Visualize the neural network\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Neural Network Architecture for Diabetes Classification')\n",
    "\n",
    "# Input layer\n",
    "for i in range(num_features):\n",
    "    plt.scatter(0, i, s=100, color='blue')\n",
    "    plt.text(0.1, i, f'Input {i+1}', fontsize=10)\n",
    "\n",
    "# Output layer\n",
    "plt.scatter(1, num_features//2, s=100, color='red')\n",
    "plt.text(1.1, num_features//2, 'Output (Sigmoid)', fontsize=10)\n",
    "\n",
    "# Weights\n",
    "W_nn, bias_nn = model_nn.layers[0].get_weights()\n",
    "max_weight = np.max(np.abs(W_nn))\n",
    "\n",
    "for i in range(num_features):\n",
    "    # Line thickness proportional to weight magnitude\n",
    "    weight = W_nn[i][0]\n",
    "    line_width = 0.5 + 3 * abs(weight) / max_weight\n",
    "    line_color = 'green' if weight > 0 else 'red'\n",
    "    plt.plot([0, 1], [i, num_features//2], linewidth=line_width, color=line_color, alpha=0.6)\n",
    "    plt.text(0.5, (i + num_features//2) / 2, f'{weight:.3f}', fontsize=8)\n",
    "\n",
    "plt.text(1.1, num_features//2 - 0.5, f'Bias: {bias_nn[0]:.3f}', fontsize=10)\n",
    "\n",
    "# Add labels\n",
    "plt.text(0, -1, 'Input Layer\\n(8 features)', ha='center', fontsize=12)\n",
    "plt.text(1, -1, 'Output Layer\\n(1 neuron, sigmoid)', ha='center', fontsize=12)\n",
    "\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(-1.5, num_features)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d59eb7",
   "metadata": {},
   "source": [
    "<h1>From scratch</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016264c",
   "metadata": {},
   "source": [
    "<h2>Modèle de régression logistic from scratch avec utilisation des matrices</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Initialisation des paramètres\n",
    "W = np.zeros((X_train.shape[1], 1))  # Shape: (8, 1) for 8 features\n",
    "b = 0.0\n",
    "\n",
    "# Reshape y_train pour garantir les dimensions adéquates \n",
    "y_train = y_train.reshape(-1, 1)  # Shape: (n_samples, 1)\n",
    "n = len(X_train)\n",
    "\n",
    "# Loss history for plotting\n",
    "loss_history = []\n",
    "\n",
    "# Entraînement (descente de gradient vectorisée)\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z = np.dot(X_train, W) + b\n",
    "    y_pred = sigmoid(z)  # Shape: (n, 1)\n",
    "    \n",
    "    # Calculate loss (binary cross-entropy)\n",
    "    loss = -np.mean(y_train * np.log(np.maximum(y_pred, 1e-15)) + \n",
    "                   (1 - y_train) * np.log(np.maximum(1 - y_pred, 1e-15)))\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    # Calculate error\n",
    "    error = y_pred - y_train  # Shape: (n, 1)\n",
    "\n",
    "    # Calcul des gradients\n",
    "    dW = (1/n) * (np.dot(X_train.T, error))  # Shape: (8, 1)\n",
    "    db = (1/n) * np.sum(error)        # Scalaire\n",
    "\n",
    "    # Mise à jour des paramètres\n",
    "    W -= learning_rate * dW\n",
    "    b -= learning_rate * db\n",
    "    \n",
    "    # Print progress occasionally\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Résultats\n",
    "print(\"Paramètres ajustés:\")\n",
    "print(f\"W = \\n{W}\")\n",
    "print(f\"b = {b:.4f}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "z_test = np.dot(X_test, W) + b\n",
    "y_pred_scratch = sigmoid(z_test)\n",
    "y_pred_classes = (y_pred_scratch > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nModel Evaluation (Logistic Regression from Scratch):\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_classes):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_classes):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_classes):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history)\n",
    "plt.title('Loss During Training (Logistic Regression from Scratch)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Compare with neural network model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "cm1 = confusion_matrix(y_test, yhat_nn_class)\n",
    "plt.imshow(cm1, cmap='Blues')\n",
    "plt.title('Neural Network Confusion Matrix')\n",
    "plt.colorbar()\n",
    "for i in range(cm1.shape[0]):\n",
    "    for j in range(cm1.shape[1]):\n",
    "        plt.text(j, i, cm1[i, j], ha='center', va='center')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "cm2 = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.imshow(cm2, cmap='Blues')\n",
    "plt.title('Logistic Regression (Scratch) Confusion Matrix')\n",
    "plt.colorbar()\n",
    "for i in range(cm2.shape[0]):\n",
    "    for j in range(cm2.shape[1]):\n",
    "        plt.text(j, i, cm2[i, j], ha='center', va='center')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(['NN', 'LR'], [accuracy_score(y_test, yhat_nn_class), accuracy_score(y_test, y_pred_classes)])\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(['NN', 'LR'], [f1_score(y_test, yhat_nn_class), f1_score(y_test, y_pred_classes)])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
